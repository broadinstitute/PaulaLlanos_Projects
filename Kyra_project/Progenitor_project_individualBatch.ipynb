{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import pycytominer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here paste the path where is located the .db file\n",
    "inputDir = \"/Users/llanos/Documents/GitHub/Kyra_project/Batch4\"\n",
    "#name of the .df file without the extension\n",
    "database_name='DS2U_DS1_Neurons_03042024_database'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLITE FILE PROCESSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such table: MyExpt_Per_Image",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[553], line 21\u001b[0m\n",
      "\u001b[1;32m     18\u001b[0m cursor\u001b[39m.\u001b[39mexecute(table_query)\n",
      "\u001b[1;32m     20\u001b[0m \u001b[39m# Add a new column named \"Metadata_genotype\" to the existing table\u001b[39;00m\n",
      "\u001b[0;32m---> 21\u001b[0m cursor\u001b[39m.\u001b[39;49mexecute(\u001b[39m'''\u001b[39;49m\u001b[39mALTER TABLE MyExpt_Per_Image\u001b[39;49m\n",
      "\u001b[1;32m     22\u001b[0m \u001b[39m                  ADD COLUMN Metadata_genotype TEXT;\u001b[39;49m\u001b[39m'''\u001b[39;49m)\n",
      "\u001b[1;32m     24\u001b[0m \u001b[39m# Update the values in the new column based on the conditions\u001b[39;00m\n",
      "\u001b[1;32m     26\u001b[0m cursor\u001b[39m.\u001b[39mexecute(\u001b[39m'''\u001b[39m\u001b[39mUPDATE MyExpt_Per_Image\u001b[39m\n",
      "\u001b[1;32m     27\u001b[0m \u001b[39m                  SET Metadata_genotype = CASE \u001b[39m\n",
      "\u001b[1;32m     28\u001b[0m \u001b[39m                                       WHEN Image_Metadata_Well LIKE \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mB\u001b[39m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m\u001b[39m OR Image_Metadata_Well LIKE \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%\u001b[39m\u001b[39mC\u001b[39m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m\u001b[39m THEN \u001b[39m\u001b[39m'\u001b[39m\u001b[39mDS2U\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;32m     29\u001b[0m \u001b[39m                                       WHEN Image_Metadata_Well LIKE \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%E\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m\u001b[39m OR Image_Metadata_Well LIKE \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%F\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m\u001b[39m THEN \u001b[39m\u001b[39m'\u001b[39m\u001b[39mDS1\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;32m     30\u001b[0m \u001b[39m                                       ELSE NULL  -- You can change this to a default value if needed\u001b[39m\n",
      "\u001b[1;32m     31\u001b[0m \u001b[39m                                       END;\u001b[39m\u001b[39m'''\u001b[39m)\n",
      "\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: MyExpt_Per_Image"
     ]
    }
   ],
   "source": [
    "# Path of the SQLite database\n",
    "database_path = f\"{inputDir}/{database_name}.db\"\n",
    "\n",
    "# Establish a connection to the SQLite database\n",
    "connection = sqlite3.connect(database_path)\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Query to retrieve table names from sqlite_master\n",
    "table_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "\n",
    "# Execute the query\n",
    "cursor.execute(table_query)\n",
    "\n",
    "# Add a new column named \"Metadata_genotype\" to the existing table\n",
    "cursor.execute('''ALTER TABLE MyExpt_Per_Image\n",
    "                  ADD COLUMN Metadata_genotype TEXT;''')\n",
    "\n",
    "# Update the values in the new column based on the conditions, for row B and C and E and F\n",
    "\n",
    "cursor.execute('''UPDATE MyExpt_Per_Image\n",
    "                  SET Metadata_genotype = CASE \n",
    "                                       WHEN Image_Metadata_Well LIKE '%B%' OR Image_Metadata_Well LIKE '%C%' THEN 'DS2U'\n",
    "                                       WHEN Image_Metadata_Well LIKE '%E%' OR Image_Metadata_Well LIKE '%F%' THEN 'DS1'\n",
    "                                       ELSE NULL  -- You can change this to a default value if needed\n",
    "                                       END;''')\n",
    "\n",
    "\n",
    "# Fetch all table names\n",
    "table_names = cursor.fetchall()\n",
    "\n",
    "\n",
    "# Rename the table in a format that can be read in the pipeline\n",
    "old_table_Image = 'MyExpt_Per_Image'\n",
    "new_table_Image = 'Image'\n",
    "old_table_Nuclei = 'MyExpt_Per_Nuclei'\n",
    "new_table_Nuclei = 'Nuclei'\n",
    "old_table_Cytoplasm = 'MyExpt_Per_Cytoplasm'\n",
    "new_table_Cytoplasm = 'Cytoplasm'\n",
    "old_table_Cells = 'MyExpt_Per_Cells'\n",
    "new_table_Cells = 'Cells'\n",
    "\n",
    "# Use the ALTER TABLE statement to rename the table\n",
    "cursor.execute(f\"ALTER TABLE {old_table_Image} RENAME TO {new_table_Image}\")\n",
    "cursor.execute(f\"ALTER TABLE {old_table_Nuclei} RENAME TO {new_table_Nuclei}\")\n",
    "cursor.execute(f\"ALTER TABLE {old_table_Cytoplasm} RENAME TO {new_table_Cytoplasm}\")\n",
    "cursor.execute(f\"ALTER TABLE {old_table_Cells} RENAME TO {new_table_Cells}\")\n",
    "\n",
    "\n",
    "#Add a new column for Image_Metadata_Table\n",
    "\n",
    "alter_query = '''\n",
    "ALTER TABLE Image\n",
    "ADD COLUMN Image_Metadata_Plate TEXT;\n",
    "'''\n",
    "\n",
    "cursor.execute(alter_query)\n",
    "\n",
    "# Update all existing rows in the Image_Metadata_Table with the string \"plate1\"\n",
    "update_query = '''\n",
    "UPDATE Image\n",
    "SET Image_Metadata_Plate = 'plate1';\n",
    "'''\n",
    "\n",
    "cursor.execute(update_query)\n",
    "\n",
    "\n",
    "# Commit the changes\n",
    "connection.commit()\n",
    "\n",
    "\n",
    "# Close the cursor and database connection\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the tables name in the database file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the table names inside of the sqlite files\n",
    "for table_name in table_names:\n",
    "    print(table_name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAKE A NEW SQLITE FILE WITH THE FOUR TABLES: Cells, Nuclei, Cytoplasm and image THAT ARE READ FOR THE PROFILING RECEIPE\n",
    "\n",
    "def copy_tables(source_db, destination_db, tables):\n",
    "    with sqlite3.connect(source_db) as source_conn:\n",
    "        with source_conn as source_cursor:\n",
    "            # Attach the destination database\n",
    "            source_cursor.execute(f\"ATTACH DATABASE '{destination_db}' AS dest\")\n",
    "\n",
    "            # Loop through the specified tables and copy them to the destination\n",
    "            for table in tables:\n",
    "                source_cursor.execute(f\"CREATE TABLE dest.{table} AS SELECT * FROM {table}\")\n",
    "\n",
    "# Replace these values with your actual database file names and table names\n",
    "source_database = f\"{inputDir}/{database_name}.db\"\n",
    "destination_database = f\"{inputDir}/{database_name}.sqlite\"\n",
    "tables_to_copy = ['Cells', 'Nuclei', 'Cytoplasm','Image']\n",
    "\n",
    "# Call the function to copy tables\n",
    "copy_tables(source_database, destination_database, tables_to_copy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GROUPING VALUES FROM EACH TABLE FROM SQLITE FILE BASED ON IMAGENUMBER COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(543, 374)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Aggregating values from each Image in Cells table\n",
    "\n",
    "connection = sqlite3.connect(f\"{inputDir}/{database_name}.db\")\n",
    "query = \"SELECT * FROM Cells\"\n",
    "data_frame_objects = pd.read_sql(query, connection)\n",
    "data_frame_objects.to_csv(f\"{inputDir}/Cells.csv\", index=False) \n",
    "\n",
    "grouped_df = data_frame_objects.groupby('ImageNumber')\n",
    "\n",
    "# Applying aggregate functions (e.g., sum, mean) to each group\n",
    "result_df_Cells = grouped_df.mean().reset_index(drop=False)\n",
    "result_df_Cells.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(543, 374)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Aggregating values from each Image in Nuclei table\n",
    "\n",
    "connection = sqlite3.connect(f\"{inputDir}/{database_name}.db\")\n",
    "query = \"SELECT * FROM Nuclei\"\n",
    "data_frame_objects = pd.read_sql(query, connection)\n",
    "data_frame_objects.to_csv(f\"{inputDir}/Nuclei.csv\", index=False) \n",
    "data_frame_objects.head()\n",
    "data_frame_objects.shape\n",
    "grouped_df = data_frame_objects.groupby('ImageNumber')\n",
    "\n",
    "# Applying aggregate functions (e.g., sum, mean) to each group\n",
    "result_df_Nuclei = grouped_df.mean().reset_index(drop=False)\n",
    "result_df_Nuclei.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(543, 188)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Aggregating values from each Image in Cytoplasm table\n",
    "\n",
    "connection = sqlite3.connect(f\"{inputDir}/{database_name}.db\")\n",
    "query = \"SELECT * FROM Cytoplasm\"\n",
    "data_frame_objects = pd.read_sql(query, connection)\n",
    "data_frame_objects.to_csv(f\"{inputDir}/Cytoplasm.csv\", index=False) \n",
    "\n",
    "#data_frame.columns\n",
    "\n",
    "grouped_df = data_frame_objects.groupby('ImageNumber')\n",
    "\n",
    "# Applying aggregate functions (e.g., sum, mean) to each group\n",
    "result_df_cytoplasm = grouped_df.mean().reset_index(drop=False)\n",
    "\n",
    "result_df_cytoplasm.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659, 443)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Aggregating values from each Image in Image table\n",
    "\n",
    "connection = sqlite3.connect(f\"{inputDir}/{database_name}.db\")\n",
    "query = \"SELECT * FROM Image\"\n",
    "data_frame_image = pd.read_sql(query, connection)\n",
    "\n",
    "data_frame_image.to_csv(f\"{inputDir}/Image.csv\", index=False) \n",
    "data_frame_image.head()\n",
    "data_frame_image.shape\n",
    "#data_frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(543, 1376)\n"
     ]
    }
   ],
   "source": [
    "# Merge the DataFrames Cells, Nuclei, Cytoplasm and Image using ImageNumber as 'ID'\n",
    "merged_df = pd.merge(result_df_Cells, result_df_Nuclei, on='ImageNumber', how='inner')\n",
    "merged_df = pd.merge(merged_df, result_df_cytoplasm, on='ImageNumber', how='inner')\n",
    "merged_df = pd.merge(merged_df, data_frame_image, on='ImageNumber', how='inner')\n",
    "merged_df.head()\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 266 empty columns:\n",
      "Index(['Image_Intensity_LowerQuartileIntensity_Brightfield_Cytoplasm',\n",
      "       'Image_Intensity_LowerQuartileIntensity_Brightfield_Mtcndr_sgmntd',\n",
      "       'Image_Intensity_LowerQuartileIntensity_Brightfield_Nuclei',\n",
      "       'Image_Intensity_LowerQuartileIntensity_Brightfield_Nuclel_sgmntd',\n",
      "       'Image_Intensity_LowerQuartileIntensity_DNA_Cytoplasm',\n",
      "       'Image_Intensity_LowerQuartileIntensity_DNA_Mitocondria_segmented',\n",
      "       'Image_Intensity_LowerQuartileIntensity_DNA_Nuclei',\n",
      "       'Image_Intensity_LowerQuartileIntensity_DNA_Nucleoli_segmented',\n",
      "       'Image_Intensity_LowerQuartileIntensity_ER_Cytoplasm',\n",
      "       'Image_Intensity_LowerQuartileIntensity_ER_Mitocondria_segmented',\n",
      "       ...\n",
      "       'Image_Intensity_UpperQuartileIntensity_Mito_Cytoplasm',\n",
      "       'Image_Intensity_UpperQuartileIntensity_Mito_Mitocondria_segmentd',\n",
      "       'Image_Intensity_UpperQuartileIntensity_Mito_Nuclei',\n",
      "       'Image_Intensity_UpperQuartileIntensity_Mito_Nucleoli_segmented',\n",
      "       'Image_Intensity_UpperQuartileIntensity_RNA_nucleoli_Cytoplasm',\n",
      "       'Image_Intensity_UpperQuartileIntensity_RNA_nucleol_Mtcndr_sgmntd',\n",
      "       'Image_Intensity_UpperQuartileIntensity_RNA_nucleoli_Nuclei',\n",
      "       'Image_Intensity_UpperQuartileIntensity_RNA_nucleoli_Nucll_sgmntd',\n",
      "       'Image_Metadata_ChannelNumber', 'Image_Metadata_FileLocation'],\n",
      "      dtype='object', length=266)\n"
     ]
    }
   ],
   "source": [
    "# Check and drop for empty columns \n",
    "\n",
    "empty_columns = merged_df.columns[merged_df.isnull().all()]\n",
    "num_empty_columns = len(empty_columns)\n",
    "\n",
    "# Display the result\n",
    "if num_empty_columns == 0:\n",
    "    print(\"No empty columns.\")\n",
    "else:\n",
    "    print(f\"There are {num_empty_columns} empty columns:\")\n",
    "    print(empty_columns)\n",
    "\n",
    "# drop empty columns\n",
    "merged_df_dropped_empty = merged_df.drop(empty_columns, axis=1)\n",
    "merged_df_dropped_empty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the first column to include the label Metadara\n",
    "sorted_df_rename = merged_df_dropped_empty.rename(columns={'Image_ImageNumber': 'Image_Metadata_ImageNumber'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Metadata_DiseaseGroup</th>\n",
       "      <th>Image_Metadata_Frame</th>\n",
       "      <th>Image_Metadata_Series</th>\n",
       "      <th>Image_Metadata_Site</th>\n",
       "      <th>Image_Metadata_Well</th>\n",
       "      <th>Image_Metadata_WellColumn</th>\n",
       "      <th>Image_Metadata_WellRow</th>\n",
       "      <th>Image_Metadata_Plate</th>\n",
       "      <th>ImageNumber</th>\n",
       "      <th>Cells_Number_Object_Number</th>\n",
       "      <th>...</th>\n",
       "      <th>Image_URL_Membrane</th>\n",
       "      <th>Image_URL_Mito</th>\n",
       "      <th>Image_URL_RNA_nucleoli</th>\n",
       "      <th>Image_Width_Brightfield</th>\n",
       "      <th>Image_Width_DNA</th>\n",
       "      <th>Image_Width_ER</th>\n",
       "      <th>Image_Width_Membrane</th>\n",
       "      <th>Image_Width_Mito</th>\n",
       "      <th>Image_Width_RNA_nucleoli</th>\n",
       "      <th>Metadata_genotype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DS2U_DS1 iN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>01</td>\n",
       "      <td>B02</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>plate4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...</td>\n",
       "      <td>file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...</td>\n",
       "      <td>file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>DS2U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DS2U_DS1 iN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>02</td>\n",
       "      <td>B02</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>plate4</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...</td>\n",
       "      <td>file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...</td>\n",
       "      <td>file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>DS2U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DS2U_DS1 iN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>07</td>\n",
       "      <td>B02</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>plate4</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...</td>\n",
       "      <td>file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...</td>\n",
       "      <td>file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>DS2U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DS2U_DS1 iN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>B02</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>plate4</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...</td>\n",
       "      <td>file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...</td>\n",
       "      <td>file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>DS2U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DS2U_DS1 iN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>B02</td>\n",
       "      <td>02</td>\n",
       "      <td>02</td>\n",
       "      <td>plate4</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...</td>\n",
       "      <td>file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...</td>\n",
       "      <td>file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>DS2U</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image_Metadata_DiseaseGroup Image_Metadata_Frame Image_Metadata_Series  \\\n",
       "0                 DS2U_DS1 iN                    0                     0   \n",
       "1                 DS2U_DS1 iN                    0                     0   \n",
       "2                 DS2U_DS1 iN                    0                     0   \n",
       "3                 DS2U_DS1 iN                    0                     0   \n",
       "4                 DS2U_DS1 iN                    0                     0   \n",
       "\n",
       "  Image_Metadata_Site Image_Metadata_Well Image_Metadata_WellColumn  \\\n",
       "0                  01                 B02                        02   \n",
       "1                  02                 B02                        02   \n",
       "2                  07                 B02                        02   \n",
       "3                  10                 B02                        02   \n",
       "4                  12                 B02                        02   \n",
       "\n",
       "  Image_Metadata_WellRow Image_Metadata_Plate  ImageNumber  \\\n",
       "0                     02               plate4            1   \n",
       "1                     02               plate4            2   \n",
       "2                     02               plate4            7   \n",
       "3                     02               plate4           10   \n",
       "4                     02               plate4           12   \n",
       "\n",
       "   Cells_Number_Object_Number  ...  \\\n",
       "0                         2.0  ...   \n",
       "1                         5.0  ...   \n",
       "2                         1.0  ...   \n",
       "3                         9.0  ...   \n",
       "4                         1.0  ...   \n",
       "\n",
       "                                  Image_URL_Membrane  \\\n",
       "0  file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...   \n",
       "1  file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...   \n",
       "2  file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...   \n",
       "3  file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...   \n",
       "4  file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...   \n",
       "\n",
       "                                      Image_URL_Mito  \\\n",
       "0  file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...   \n",
       "1  file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...   \n",
       "2  file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...   \n",
       "3  file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...   \n",
       "4  file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...   \n",
       "\n",
       "                              Image_URL_RNA_nucleoli  Image_Width_Brightfield  \\\n",
       "0  file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...                     1080   \n",
       "1  file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...                     1080   \n",
       "2  file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...                     1080   \n",
       "3  file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...                     1080   \n",
       "4  file:///Z:/Kyra_Export_PB/USE_THESIS%20iN%20DS...                     1080   \n",
       "\n",
       "   Image_Width_DNA  Image_Width_ER  Image_Width_Membrane  Image_Width_Mito  \\\n",
       "0             1080            1080                  1080              1080   \n",
       "1             1080            1080                  1080              1080   \n",
       "2             1080            1080                  1080              1080   \n",
       "3             1080            1080                  1080              1080   \n",
       "4             1080            1080                  1080              1080   \n",
       "\n",
       "   Image_Width_RNA_nucleoli  Metadata_genotype  \n",
       "0                      1080               DS2U  \n",
       "1                      1080               DS2U  \n",
       "2                      1080               DS2U  \n",
       "3                      1080               DS2U  \n",
       "4                      1080               DS2U  \n",
       "\n",
       "[5 rows x 1110 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sort the Metadata columns. The first column should be the ones that contain the metadata.\n",
    "\n",
    "columns = merged_df_dropped_empty.columns\n",
    "\n",
    "\n",
    "sorted_columns = sorted(columns, key=lambda x: x.startswith(\"Image_Metadata\"), reverse=True)\n",
    "\n",
    "# Create a new DataFrame with sorted columns\n",
    "sorted_df = merged_df_dropped_empty[sorted_columns]\n",
    "sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dataset sorted \n",
    "sorted_df.to_csv(f\"{inputDir}/sorted_df.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the Image prefix in the columns.\n",
    "sorted_df.columns = [col.replace('Image_Metadata', 'Metadata') if 'Image_Metadata' in col else col for col in sorted_df.columns]\n",
    "sorted_df.to_csv(f\"{inputDir}/sorted_df.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "1010\n"
     ]
    }
   ],
   "source": [
    "# Extract column names with 'Metadata'\n",
    "metadata_columns = [col for col in sorted_df.columns if 'Metadata' in col]\n",
    "print(len(metadata_columns))\n",
    "\n",
    "# Extract column names with 'Cells', 'Nuclei', or 'Cytoplasm'\n",
    "cell_related_columns = [col for col in sorted_df.columns if any(keyword in col for keyword in ['Cells', 'Nuclei', 'Cytoplasm'])]\n",
    "print(len(cell_related_columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract column names with 'Image' prefix, excluding those already in cell_related_columns\n",
    "image_columns = [col for col in sorted_df.columns if col.startswith('Image') and col not in cell_related_columns and col not in metadata_columns]\n",
    "\n",
    "\n",
    "# Determine the remaining columns\n",
    "other_columns = [col for col in sorted_df.columns if col not in metadata_columns + cell_related_columns + image_columns]\n",
    "\n",
    "\n",
    "# Concatenate the column lists in the desired order\n",
    "sorted_columns_final = metadata_columns + other_columns + cell_related_columns + image_columns\n",
    "\n",
    "\n",
    "# Create a new DataFrame with the sorted columns\n",
    "sorted_df_final = sorted_df[sorted_columns_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly convert all non-metadata columns to float\n",
    "# in the original df ALL columns are of type object and that breaks pycytominer\n",
    "for col in sorted_df_final.columns:\n",
    "    if 'Nuclei' in col or 'Cells' in col or 'Cytoplasm' in col or 'ImageNumber' in col:\n",
    "        sorted_df_final[col] = sorted_df_final[col].astype(float)\n",
    "#print([df.dtypes])\n",
    "\n",
    "sorted_df_final.to_csv(f\"{inputDir}/sorted_df_final.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate columns found.\n"
     ]
    }
   ],
   "source": [
    "#Check if there is come columns duplicated\n",
    "duplicated_columns = sorted_df_final[sorted_df_final.duplicated()]\n",
    "\n",
    "if len(duplicated_columns) > 0:\n",
    "    print(f\"Duplicate columns found: {', '.join(duplicated_columns)}\")\n",
    "else:\n",
    "    print(\"No duplicate columns found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns have two objects contained in the name, as nuclei and cytoplasm, which bring error because the code expect to find columns with Nuclei, Cells OR Cytoplasm, not two of them together. Then, we define a different name for the suffix to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the substrings to replace\n",
    "substrings_to_replace = ['_Nuclei']\n",
    "replacement_substrings = ['_Nucle']\n",
    "\n",
    "# Replace substrings in column names\n",
    "sorted_df_final.columns = [col.replace(old, new) for col in sorted_df_final.columns for old, new in zip(substrings_to_replace, replacement_substrings)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the substrings to replace\n",
    "substrings_to_replace = ['_Cells']\n",
    "replacement_substrings = ['_Cell']\n",
    "\n",
    "# Replace substrings in column names\n",
    "sorted_df_final.columns = [col.replace(old, new) for col in sorted_df_final.columns for old, new in zip(substrings_to_replace, replacement_substrings)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the substrings to replace\n",
    "substrings_to_replace = ['_Cytoplasm']\n",
    "replacement_substrings = ['_Cytoplas']\n",
    "\n",
    "# Replace substrings in column names\n",
    "sorted_df_final.columns = [col.replace(old, new) for col in sorted_df_final.columns for old, new in zip(substrings_to_replace, replacement_substrings)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter columns that contain \"Nuclei,\" \"Cytoplasm,\" and \"Cells\" and concatenate in a dataframe\n",
    "filtered_df = sorted_df_final.filter(like='Nuclei').join(sorted_df_final.filter(like='Cytoplasm')).join(sorted_df_final.filter(like='Cells'))\n",
    "filtered_df.to_csv(f\"{inputDir}/filtered_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get column names that start with \"Metadata_\"\n",
    "metadata_column_names = [col for col in sorted_df_final.columns if col.startswith('Metadata_')]\n",
    "\n",
    "# Create a new DataFrame with the filtered columns\n",
    "Columns_metadata = sorted_df_final[metadata_column_names]\n",
    "Columns_metadata.to_csv(f\"{inputDir}/Columns_metadata.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the aggregation functions\n",
    "#This will aggregate by Well all the features measurments that come from the same Well defined in Metadata_Well column\n",
    "aggregations = {\n",
    "    'Metadata_Well': 'first',  # Take the first value as it's the same for each group\n",
    "    **{col: ['mean', 'median', 'std', 'min', 'max'] for col in filtered_df.columns}\n",
    "}\n",
    "# Group by \"Metadata_ImageNumber\" and aggregate the statistics for columns with the specified prefix\n",
    "# The .agg (aggregate) method applies the listed operations to all values grouped by ImageNumber\n",
    "well_agg_df = sorted_df_final.groupby(['Metadata_Well','Metadata_genotype'], sort=False).agg(aggregations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mm/mp46tk592c10r7w5n0vwcclc0000gq/T/ipykernel_64893/292143542.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  well_agg_df.reset_index(inplace=True)\n",
      "/var/folders/mm/mp46tk592c10r7w5n0vwcclc0000gq/T/ipykernel_64893/292143542.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  well_agg_df.reset_index(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Flatten MultiIndex columns\n",
    "well_agg_df.columns = well_agg_df.columns.map('_'.join)\n",
    "\n",
    "# Reset index to move 'Metadata_ImageNumber' to a regular column\n",
    "well_agg_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_agg_df.head()\n",
    "well_agg_df.to_csv(f\"{inputDir}/well_agg_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_agg_df = pd.read_csv(\"/Users/llanos/Documents/GitHub/Kyra_project/Batch3/well_agg_df.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One we got our features aggregated by Well we can normalize. The neuron dataset was normalized based on the negative control assigned to each group, this example is done for the Grpup WC, and the control used was WCB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4663)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pycytominer.normalize(\n",
    "    profiles=well_agg_df,    #the dataframe containing the CellProfiler features\n",
    "    #features=feature_cols,   #list of features to normalize; if \"infer\", anything starting with 'Cells', 'Nuclei' or 'Cytoplasm'\n",
    "    #meta_features=metadata_cols,   #list of metadata columns; if \"infer\" (default), any column starting with 'Metadata_'\n",
    "    image_features=False,  #Whether the profiles contain image features\n",
    "    samples=\"Metadata_genotype=='WCB'\",     #The metadata column values to use as a normalization reference. Defaults to \"all\".\n",
    "    method=\"mad_robustize\",    #How to normalize the dataframe. Defaults to \"standardize\". \"mad_robustize\" is used in the profiling recipe by default\n",
    "    mad_robustize_epsilon=0, # The mad_robustize fudge factor parameter. Set this to 0 if mad_robustize generates features with large values.\n",
    "    output_file=f\"{inputDir}/data_normalized_WC.csv\" \n",
    ")\n",
    "df_norm = pd.read_csv(f\"{inputDir}/data_normalized_WC.csv\")\n",
    "df_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step should be run if you already generate 2 dataframes for each group, DS and WC. Once you got those 2 dataframe or csv you can do the feature selection.\n",
    "CONCATENATE BEFORE FUTURE SELECT:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm_DS = pd.read_csv(f\"{inputDir}/data_normalized.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4663)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_norm_DS.shape #checking the shape of the DS group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4663)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_norm.shape #checking the shape of the WC group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate plates\n",
    "\n",
    "df_norm_WC_DS = pd.concat([df_norm, df_norm_DS], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 4663)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking the new shape\n",
    "df_norm_WC_DS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 1439)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pycytominer.feature_select(\n",
    "    profiles=df_norm_WC_DS,\n",
    "    #features=feature_cols,   #list of features to normalize; if \"infer\", anything starting with 'Cells', 'Nuclei' or 'Cytoplasm'\n",
    "    image_features=False,  #Whether the profiles contain image features\n",
    "    operation=['variance_threshold','correlation_threshold', 'drop_na_columns', 'blocklist', 'drop_outliers'],   #add outlier removal to get rid of \n",
    "    outlier_cutoff=500, #500 is the default\n",
    "    output_file=f\"{inputDir}/data_normalized_featureSelected_WC_DS_bygenotype.csv\", \n",
    "    samples='all', #Samples to provide operation on.Str or list. Defaults to 'all' ...I don't get it\n",
    ")\n",
    "df_ftsel_WC_DS = pd.read_csv(f\"{inputDir}/data_normalized_featureSelected_WC_DS_bygenotype.csv\")\n",
    "df_ftsel_WC_DS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the shape and save the future selected file\n",
    "df_ftsel_WC_DS.shape\n",
    "df_ftsel_WC_DS.to_csv(f\"{inputDir}/df_ftsel_WC_DS.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder and transpose df for easier import into Morpheus\n",
    "df_ftsel_WC_DS = df_ftsel_WC_DS.T\n",
    "\n",
    "#save to final .csv\n",
    "# Index=True is necessary so that we save the row labels into the .csv\n",
    "df_ftsel_WC_DS.to_csv(f\"{inputDir}/data_forMorpheus_WC_DS_by_genotype.csv\",sep=',',encoding=\"utf-8\",header=False,index=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
